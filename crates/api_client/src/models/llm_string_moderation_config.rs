/*
 * afrodite-backend
 *
 * Dating app backend API
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct LlmStringModerationConfig {
    #[serde(rename = "add_llm_output_to_user_visible_rejection_details", skip_serializing_if = "Option::is_none")]
    pub add_llm_output_to_user_visible_rejection_details: Option<bool>,
    /// If LLM response starts with this text or the first line of the response contains this text, the profile text is moderated as accepted. The comparisons are case insensitive.
    #[serde(rename = "expected_response")]
    pub expected_response: String,
    #[serde(rename = "max_tokens", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<Option<i32>>,
    #[serde(rename = "move_rejected_to_human_moderation")]
    pub move_rejected_to_human_moderation: bool,
    #[serde(rename = "system_text")]
    pub system_text: String,
    /// Placeholder \"{text}\" is replaced with text which will be moderated.
    #[serde(rename = "user_text_template")]
    pub user_text_template: String,
}

impl LlmStringModerationConfig {
    pub fn new(expected_response: String, move_rejected_to_human_moderation: bool, system_text: String, user_text_template: String) -> LlmStringModerationConfig {
        LlmStringModerationConfig {
            add_llm_output_to_user_visible_rejection_details: None,
            expected_response,
            max_tokens: None,
            move_rejected_to_human_moderation,
            system_text,
            user_text_template,
        }
    }
}

