/*
 * afrodite-backend
 *
 * Dating app backend API
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct AdminContentModerationConfig {
    #[serde(rename = "added_content")]
    pub added_content: bool,
    #[serde(rename = "default_action")]
    pub default_action: models::ModerationAction,
    #[serde(rename = "initial_content")]
    pub initial_content: bool,
    /// Large language model based moderation. Actions: reject (can be replaced with move_to_human or ignore) and          accept (can be replaced with move_to_human or delete).
    #[serde(rename = "llm_primary", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub llm_primary: Option<Option<Box<models::LlmContentModerationConfig>>>,
    /// The secondary LLM moderation will run if primary results with ignore action.
    #[serde(rename = "llm_secondary", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub llm_secondary: Option<Option<Box<models::LlmContentModerationConfig>>>,
    /// Neural network based detection. Actions: reject, move_to_human, accept and delete.
    #[serde(rename = "nsfw_detection", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub nsfw_detection: Option<Option<Box<models::AdminNsfwDetectionConfig>>>,
}

impl AdminContentModerationConfig {
    pub fn new(added_content: bool, default_action: models::ModerationAction, initial_content: bool) -> AdminContentModerationConfig {
        AdminContentModerationConfig {
            added_content,
            default_action,
            initial_content,
            llm_primary: None,
            llm_secondary: None,
            nsfw_detection: None,
        }
    }
}

